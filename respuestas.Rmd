---
title: 'Tipologia y ciclo de vida de los datos: Práctica 2'
author: 'Autor: Sandra Garrido Romero'
date: "Diciembre 2019"
output:
  word_document:
    toc: yes
    toc_depth: '2'
  pdf_document: default
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, include=FALSE}
options(tinytex.verbose = TRUE)

```
# Presentación
En esta práctica se elabora un caso práctico orientado a aprender a identificar los datos
relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación
y análisis de las mismas. Para hacer esta práctica tendréis que trabajar en grupos de 2 personas.
Tendréis que entregar un solo archivo con el enlace Github (https://github.com) donde se
encuentren las soluciones incluyendo los nombres de los componentes del equipo. Podéis utilizar
la Wiki de Github para describir vuestro equipo y los diferentes archivos que corresponden a
vuestra entrega. Cada miembro del equipo tendrá que contribuir con su usuario Github. Aunque
no se trata del mismo enunciado, los siguientes ejemplos de ediciones anteriores os pueden
servir como guía:
* Ejemplo: https://github.com/Bengis/nba-gap-cleaning
* Ejemplo complejo (archivo adjunto).

# Competencias
En esta práctica se desarrollan las siguientes competencias del Máster de Data Science:

* Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación
y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.

* Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración,
transformación, limpieza y validación) para su posterior análisis.

# Objetivos

Los objetivos concretos de esta práctica son:

* Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de
problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o
multidisciplinares.

* Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza
y validación) para llevar a cabo un proyecto analítico.

* Aprender a analizar los datos adecuadamente para abordar la información contenida en
los datos.

* Identificar la mejor representación de los resultados para aportar conclusiones sobre el
problema planteado en el proceso analítico.

* Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.

* Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un
modo que tendrá que ser en gran medida autodirigido o autónomo.

* Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el
ámbito de la ciencia de datos.

# Resolución
## Descripción del dataset

El conjunto de datos a utilizar se ha descargado desde este enlace https://www.kaggle.com/c/titanic/data de la página web de _Kaggle_. Este dataset se conforma de 12 variables (columnas) y 1309 pasajeros (filas). El conjunto de datos se ha conseguido uniendo los conjuntos de entrenamiento y test. Los campos del conjunto de datos son los siguientes:

* __PassengerId__: Identificador de cada uno de los pasajeros.
* __Survived__: Indica si el pasajero sobrevivió (1) o no (0). 
* __Pclass__: Clase que figuraba en el ticket: primera clase (1), segunda clase (2) o tercera clase (3).
* __Name__ : Nombre del pasajero.
* __Sex__ : Sexo del pasajero (male, female).
* __Age__ : Edad del pasajero.
* __SibSp__ : Relaciones familiares del siguiente tipo: hermanos, hermanastros, esposos o esposas.
* __Parch__ : Relaciones familiares del siguiente tipo: madre, padre, hijos o hijastros.
* __Ticket__ : Número de ticket.
* __Fare__ : Precio del ticket.
* __Cabin__ : Número de cabina.
* __Embarked__ : Puerto de embarque: Cherbourg (C), Queenstown (Q) o Southampton (S).

### Importancia y objetivos de los análisis

Este conjunto de datos puede ayudar a resolver qué variables son las que influyen en si un pasajero sobrevivió al hundimiento del Titanic o no.

## Integración y selección de los datos

En primer lugar, se va a proceder a leer el fichero de datos obtenido de internet. Se cuenta con dos ficheros CSV, por un lado, el fichero de datos de entrenamiento y por otro, el fichero de datos test. Se van a importar los dos archivos y se van a unir en un sólo _data.frame_:
```{r message=FALSE}
#Lectura del fichero test
test <- read.csv('test.csv',stringsAsFactors = FALSE)
#Letura del fichero entrenamiento
train <- read.csv('train.csv',stringsAsFactors = FALSE)
# Unión de los dos conjuntos importados en uno solo
library(dplyr)
datos <- bind_rows(train,test)
```
Se observa una parte de los datos y el tipo de estos:
```{r}
head(datos)
str(datos)
```
Más adelante se tratará el tipo de los datos.

## Limpieza de los datos

En este apartado se va a proceder a limpiar los datos de manera que no contengan valores vacíos o valores extremos.

### Ceros y elementos vacíos

En primer lugar, se procede a comprobar si existen valores nulos en el conjunto:
```{r}
colSums(is.na(datos))
```
Existen valores nulos en las variables _Survived_, _Age_ y _Fare_.

Se buscan valores vacíos:
```{r}
colSums(datos=="")
```
Las siguientes columnas presentan valores vacíos: _Cabin_ y _Embarked_.

Los valores nulos de la variable _Edad_ se van a rellenar con la media del resto de edades.
```{r}
datos$Age[is.na(datos$Age)] <- mean(datos$Age,na.rm=T)
```

Los valores de la variable _Survived_ nulos corresponden a los registros procedentes del archivo de datos test.

Los valores de _Cabin_ y _Fare_ vacíos no se van a tratar ya que es una variable que no tiene repercusión en el análisis.

Los valores _Embarked_ vacíos se van a sustituir por "S" que representa el puerto de salida del barco.

```{r}
datos$Embarked[datos$Embarked==""]="S"
```

Algunos de los tipos que R ha asignado a los datos se deben cambiar de tipo _int_ a tipo _factor_ ya que son variables que clasifican a los datos.
```{r}
datos$Survived<-as.factor(datos$Survived)
datos$Pclass<-as.factor(datos$Pclass)
datos$Sex<-as.factor(datos$Sex)
datos$Embarked<-as.factor(datos$Embarked)
```
Se comprueba que la conversión se ha realizado correctamente:
```{r}
str(datos)
```

### Valores extremos

Los valores extremos son aquellos que distan mucho del resto de valores del conjunto de datos. Se va a utilizar la función _boxplots.stats()_ de R para determinar qué valores extremos contiene cada variable. Los valores extremos se van a buscar en las variables numéricas.

```{r}
boxplot.stats(datos$Age)$out
```
Los valores extremos que aparecen en la variable _Age_ se van a dejar como están ya que aparecen debido a que las edades de los pasajeros son muy variadas dado la existencia de bebés y personas mayores a bordo del barco.
```{r}
boxplot.stats(datos$SibSp)$out
```
Los valores extremos de _SibSp_ tampoco se van a tratar ya que es perfectamente válido que haya personas con muchos familiares a bordo.
```{r}
boxplot.stats(datos$Parch)$out
```
Con la variable _Parch_ ocurre lo mismo que con la anterior.
```{r}
boxplot.stats(datos$Fare)$out
```
Por último, los valores extremos de la variable _Fare_ también se van a dejar como están porque el precio entre los billetes de primera y tercera clase varían mucho.

Se exporta el conjunto de datos preprocesado a un nuevo fichero:
Se exporta el conjunto de datos a un nuevo archivo.
```{r}
write.csv(datos,"datos_clean.csv")
```

## Análisis de los datos

### Selección de los grupos de datos a analizar

En primer lugar, se tienen los grupos de datos divididos en datos de entrenamiento y datos test tal cual se han descargado de la página web.

Para obtener más agrupaciones de los datos, se van a dividir según el valor de distintas variables.

```{r}
# Agrupación por supervivientes
datos.survived<-datos[datos$Survived=="1",]
datos.nosurvived<-datos[datos$Survived=="1",]

# Agrupación por clase
datos.primera<-datos[datos$Pclass=="1",]
datos.segunda<-datos[datos$Pclass=="2",]
datos.tercera<-datos[datos$Pclass=="3",]

# Agrupación por sexo
datos.mujer<-datos[datos$Sex=="female",]
datos.hombre<-datos[datos$Sex=="male",]
```
### Comprobación de la normalidad y homogeneidad de la varianza

La comprobación de la normalidad de las variables numéricas se llevará a cabo mediante la prueba de _Pearson__Wilk_. En este caso, las variables que se estudiarán son _Age_, _SibSp_, _Parch_ y _Fare_.

Se parte de la hipótesis nula de que las muestras provienen de una distribución normal, y de la hipótesis alternativa de que las muestras no provienen de distribuciones normales.

El nivel de significancia que se utilizará es 0,05. Si el p-valor obtenido en la prueba es menor que 0,05 entonces se rechara la hipótesis nula.

```{r}
shapiro.test(datos[,6])
shapiro.test(datos[,7])
shapiro.test(datos[,8])
shapiro.test(datos[,10])
```
Además, se va a aplicar la prueba de _Pearson_ para comprobar si se obtienen los mismo resultados.
```{r}
library("nortest")
pearson.test(datos[,6])
pearson.test(datos[,7])
pearson.test(datos[,8])
pearson.test(datos[,10])
```

Todas las pruebas realizadas han obtenido un p-valor menor al nivel de significancia prefijado, por lo que se rechaza la hipótesis nula en todos los casos. Ninguna de las variables estudiadas sigue una distribución normal.

Aún así, al contar con más de 30 registros, por el teorema central del límite, los datos se pueden normalizar.

Se va a estudiar la homogeneidad de varianzas en la variable _Age_ en función de los grupos que se han creado anteriormente. Se parte de la hipótesis nula de que las varianzas de las muestras son iguales, y de la hipótesis alternativa de que no son iguales. El nivel de significancia utilizado será 0,05.

```{r}
# En función del sexo
fligner.test(datos$Age ~ datos$Sex, data = datos)
# En función de si sobrevivió o no
fligner.test(datos$Age ~ datos$Survived, data = datos)
# En función de la clase en la que viajaban
fligner.test(datos$Age ~ datos$Pclass, data = datos)
```
Los p-valor obtenidos en cada una de las pruebas son menores a 0,05 por lo que se rechaza la hipótesis de que las varianzas son homogéneas.

### Pruebas estadisticas

Se obtiene una matriz de porcentajes de frecuencias de la variable _Sex_ en función de si el pasajero sobrevivió o no.
```{r}
filas=dim(datos)[1]
t<-table(datos[1:filas,]$Sex,datos[1:filas,]$Survived)
for (i in 1:dim(t)[1]){
    t[i,]<-t[i,]/sum(t[i,])*100
}
t
```
En la tabla se puede ver que las mujeres tenían más probabilidad de sobrevivir que los hombres.

Como se dispone de un conjunto de datos de entrenamiento y otro de test, se va a crear un árbol de decisión para comprobar si se predicen los datos correctamente.

```{r}
y <- datos[,2] 
X <- select(datos,Pclass,Sex,Embarked)
trainX <- X[1:891,]
trainy <- y[1:891]
model <- C50::C5.0(trainX, trainy,rules=TRUE )
summary(model)
```

Se utilizan los datos pertenecientes al conjunto test y se comparan con los que se encuentran en el archivo _gender_submission.csv_. La matriz de confusión servirá para comprobar si el modelo creado clasifica correctamente los datos.
```{r}
testX <- X[892:1309,]
testy <- read.csv('gender_submission.csv',stringsAsFactors = FALSE)
testy<-testy$Survived
predicted_model <- predict( model, testX, type="class" )
mat_conf<-table(testy,Predicted=predicted_model)
mat_conf
```
Los no supervivientes se predicen correctamente pero, hay fallos en los supervivientes.

## Representación de resultados

Se van a representar las variables de tipo _factor_ en función de si el personaje sobrevivió o no, para ver si concuerda con los resultados obtenidos.

```{r}
library(ggplot2)
train<-datos[1:891,]
ggplot(train,aes(Pclass,fill=Survived))+geom_bar() +labs(x="Class", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("black","#008000"))+ggtitle("Survived by Class")
ggplot(train,aes(Sex,fill=Survived))+geom_bar() +labs(x="Sex", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("black","#008000"))+ggtitle("Survived by Sex")
ggplot(train,aes(Embarked,fill=Survived))+geom_bar() +labs(x="Embarked", y="Passengers")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("black","#008000"))+ggtitle("Survived by Embarked")
```


## Conclusiones
